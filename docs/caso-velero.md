# Case Detalhado: Otimiza√ß√£o do Namespace Velero

## üìä Resumo Executivo

**Namespace:** velero  
**Tipo:** Backup e Disaster Recovery  
**Resultado:** Redu√ß√£o de 92% no desperd√≠cio de CPU (560m ‚Üí 45m)  
**Impacto:** Zero downtime, performance mantida, 515m de CPU liberados

---

## üîç Contexto

O Velero √© uma ferramenta de backup e disaster recovery para Kubernetes. No cluster auditado, ele possu√≠a:

- **3 pods de node-agent** (DaemonSet) - um por n√≥
- **1 pod velero** (Deployment) - controle central

### Situa√ß√£o Inicial

```
NAMESPACE   REQUESTED   USED    SLACK    WASTE %
velero      560m        6m      554m     98.9% üî¥
```

**Detalhamento por Pod:**

| Pod | Tipo | Request | Uso Real | Desperd√≠cio |
|-----|------|---------|----------|-------------|
| node-agent (3x) | DaemonSet | 20m cada | ~1m cada | 95% |
| velero | Deployment | 500m | ~5m | 99% |

---

## üîé Diagn√≥stico

### 1. Coleta de Dados Inicial

```bash
# Verificar requests configurados
kubectl get pods -n velero -o custom-columns='NAME:.metadata.name,CPU_REQ:.spec.containers[*].resources.requests.cpu,MEM_REQ:.spec.containers[*].resources.requests.memory'

# Output:
NAME                     CPU_REQ   MEM_REQ
node-agent-4mc7m         20m       128Mi
node-agent-bxpd4         20m       128Mi
node-agent-zfzx9         20m       128Mi
velero-b655f5996-jfsfv   500m      128Mi
```

### 2. An√°lise de Uso Real

```bash
# Verificar uso atual
kubectl top pods -n velero

# Output:
NAME                     CPU(cores)   MEMORY(bytes)
node-agent-4mc7m         1m           28Mi
node-agent-bxpd4         1m           27Mi
node-agent-zfzx9         1m           26Mi
velero-b655f5996-jfsfv   5m           245Mi
```

### 3. Valida√ß√£o com Prometheus/Grafana

Analisando 7 dias de hist√≥rico no Grafana:

**node-agent:**
- Uso m√©dio: 0.0005 cpu (~0.5m)
- Uso de pico: 0.0007 cpu (~0.7m)
- Padr√£o: Extremamente est√°vel, sem picos significativos

**velero:**
- Uso m√©dio: 0.005 cpu (~5m)
- Uso de pico: 0.015 cpu (~15m)
- Padr√£o: Uso baixo e constante, com picos ocasionais (provavelmente durante execu√ß√£o de backups)

### 4. An√°lise de Workload

**node-agent:**
- Fun√ß√£o: Coletar dados dos volumes persistentes em cada n√≥
- Carga: Leve, apenas monitora mudan√ßas nos volumes
- Picos: Apenas durante snapshots (poucos segundos)

**velero:**
- Fun√ß√£o: Controlador central, orquestra backups e restores
- Carga: Leve na maior parte do tempo, picos durante opera√ß√µes de backup
- Frequ√™ncia de backups: Di√°ria (cronjob)

---

## üéØ Estrat√©gia de Otimiza√ß√£o

### C√°lculo dos Novos Valores

**node-agent:**
```
Uso de pico: 0.7m
Margem de seguran√ßa: 7x
Request recomendado: 0.7m √ó 7 ‚âà 5m ‚úÖ
```

**velero:**
```
Uso de pico: 15m
Margem de seguran√ßa: 2x
Request recomendado: 15m √ó 2 = 30m ‚úÖ
```

### Por que Estas Margens?

- **node-agent (7x)**: Margem alta pois s√£o DaemonSets cr√≠ticos e uso √© extremamente previs√≠vel
- **velero (2x)**: Margem menor mas suficiente, considerando que picos s√£o raros e curtos

---

## üõ†Ô∏è Implementa√ß√£o

### Script de Corre√ß√£o Criado

```bash
#!/bin/bash
# correcao_velero.sh

echo "üöÄ Aplicando otimiza√ß√£o no namespace velero..."

# 1. Corrigir DaemonSet node-agent (20m ‚Üí 5m)
kubectl patch daemonset node-agent -n velero --type='json' \
  -p='[{"op": "replace", "path": "/spec/template/spec/containers/0/resources/requests/cpu", "value": "5m"}]'

echo "‚úì DaemonSet node-agent atualizado"

# 2. Corrigir Deployment velero (500m ‚Üí 30m)
kubectl patch deployment velero -n velero --type='json' \
  -p='[{"op": "replace", "path": "/spec/template/spec/containers/0/resources/requests/cpu", "value": "30m"}]'

echo "‚úì Deployment velero atualizado"
echo ""
echo "Aguardando rollout..."
sleep 10

# 3. Validar novos valores
echo "üìä Novos valores configurados:"
kubectl get pods -n velero -o custom-columns='NAME:.metadata.name,CPU_REQ:.spec.containers[*].resources.requests.cpu'
```

### Execu√ß√£o

```bash
chmod +x correcao_velero.sh
./correcao_velero.sh
```

### Output da Execu√ß√£o

```
üöÄ Aplicando otimiza√ß√£o no namespace velero...
daemonset.apps/node-agent patched
‚úì DaemonSet node-agent atualizado
deployment.apps/velero patched
‚úì Deployment velero atualizado

Aguardando rollout...

üìä Novos valores configurados:
NAME                     CPU_REQ
node-agent-4xhcx         5m
node-agent-7lq5p         5m
node-agent-zhkv2         5m
velero-8766b5d9d-2rvcn   30m
```

---

## ‚úÖ Valida√ß√£o

### 1. Verifica√ß√£o de Pods

```bash
# Pods recriados com sucesso
kubectl get pods -n velero

NAME                      READY   STATUS    RESTARTS   AGE
node-agent-4xhcx          1/1     Running   0          2m
node-agent-7lq5p          1/1     Running   0          2m
node-agent-zhkv2          1/1     Running   0          2m
velero-8766b5d9d-2rvcn    1/1     Running   0          1m
```

### 2. Confirma√ß√£o de Valores

```bash
kubectl get pods -n velero -o custom-columns='NAME:.metadata.name,CPU_REQ:.spec.containers[*].resources.requests.cpu,MEM_REQ:.spec.containers[*].resources.requests.memory'

NAME                     CPU_REQ   MEM_REQ
node-agent-4xhcx         5m        128Mi     ‚úÖ (antes: 20m)
node-agent-7lq5p         5m        128Mi     ‚úÖ (antes: 20m)
node-agent-zhkv2         5m        128Mi     ‚úÖ (antes: 20m)
velero-8766b5d9d-2rvcn   30m       128Mi     ‚úÖ (antes: 500m)
```

### 3. Monitoramento P√≥s-Mudan√ßa

**Ap√≥s 24 horas:**
```bash
kubectl top pods -n velero

NAME                     CPU(cores)   MEMORY(bytes)
node-agent-4xhcx         1m           29Mi    ‚úÖ Est√°vel
node-agent-7lq5p         1m           28Mi    ‚úÖ Est√°vel
node-agent-zhkv2         1m           27Mi    ‚úÖ Est√°vel
velero-8766b5d9d-2rvcn   6m           246Mi   ‚úÖ Est√°vel
```

### 4. Teste Funcional

```bash
# Executar backup manual para testar
velero backup create test-backup-pos-otimizacao

# Verificar se backup foi conclu√≠do com sucesso
velero backup describe test-backup-pos-otimizacao

# Output:
Phase: Completed ‚úÖ
Errors: 0
Warnings: 0
```

### 5. Verifica√ß√£o de Eventos

```bash
# Nenhum evento de erro relacionado a recursos
kubectl get events -n velero --sort-by='.lastTimestamp' | tail -20

# Sem OOMKilled ‚úÖ
# Sem CPU throttling ‚úÖ
# Sem Eviction ‚úÖ
```

---

## üìä Resultados

### Antes vs Depois

| M√©trica | Antes | Depois | Melhoria |
|---------|-------|--------|----------|
| **CPU Total Requested** | 560m | 45m | **-92%** |
| **CPU Total Used** | ~6m | ~6m | 0% |
| **Desperd√≠cio (Slack)** | 554m | 39m | **-93%** |
| **Desperd√≠cio (%)** | 98.9% | 86.7% | **-12.2pp** |
| **Margem de Seguran√ßa** | 93x | 7.5x | Mais saud√°vel |
| **Downtime** | - | 0 seg | ‚úÖ |
| **Problemas** | - | 0 | ‚úÖ |

### Impacto no Cluster

**Recursos Liberados:**
- 515 millicores de CPU
- Equivalente a ~51% de uma CPU completa
- Permite executar dezenas de pods adicionais

**Distribui√ß√£o do Ganho:**
```
Total liberado: 515m
‚îú‚îÄ‚îÄ node-agent (3x): 45m (15m √ó 3)
‚îî‚îÄ‚îÄ velero: 470m
```

### ROI (Return on Investment)

**Se o cluster fosse cloud:**
- Economia estimada: ~$20-30/m√™s (apenas CPU)
- Payback do esfor√ßo: < 1 dia
- ROI anual: ~$240-360

---

## üí° Li√ß√µes Aprendidas

### O que Funcionou Bem

1. **An√°lise de Hist√≥rico:** 7 dias de m√©tricas deram confian√ßa para definir valores
2. **Abordagem Gradual:** Come√ßar pelo namespace menos cr√≠tico reduziu riscos
3. **Automa√ß√£o:** Script reutiliz√°vel facilita aplica√ß√£o em outros namespaces
4. **Margem de Seguran√ßa:** Manter requests 5-7x o uso real evitou problemas

### Insights T√©cnicos

1. **DaemonSets s√£o previs√≠veis:** Uso extremamente est√°vel, margem alta √© segura
2. **Backups s√£o espor√°dicos:** Picos curtos n√£o justificam requests altos
3. **Default √© gen√©rico:** Valores padr√£o s√£o sempre superestimados

### Pr√≥ximas Otimiza√ß√µes

Namespaces similares identificados:
- **istio-system** (98.5% desperd√≠cio) - Service mesh
- **longhorn-system** (82.4% desperd√≠cio) - Storage
- **cattle-monitoring-system** (88.3% desperd√≠cio) - Observabilidade

---

## üîÑ Processo de Revers√£o

Caso necess√°rio reverter:

```bash
# Reverter DaemonSet
kubectl rollout undo daemonset/node-agent -n velero

# Reverter Deployment
kubectl rollout undo deployment/velero -n velero

# Ou aplicar valores originais manualmente
kubectl patch daemonset node-agent -n velero --type='json' \
  -p='[{"op": "replace", "path": "/spec/template/spec/containers/0/resources/requests/cpu", "value": "20m"}]'

kubectl patch deployment velero -n velero --type='json' \
  -p='[{"op": "replace", "path": "/spec/template/spec/containers/0/resources/requests/cpu", "value": "500m"}]'
```

**Observa√ß√£o:** Revers√£o n√£o foi necess√°ria. Mudan√ßas foram bem-sucedidas.

---

## üìö Refer√™ncias

- [Velero Documentation](https://velero.io/docs/)
- [Kubernetes Resource Management](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/)
- [DaemonSet Best Practices](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/)

---

## üéì Compet√™ncias Demonstradas

- ‚úÖ An√°lise de m√©tricas e observabilidade
- ‚úÖ Kubernetes resource management avan√ßado
- ‚úÖ Scripting e automa√ß√£o
- ‚úÖ Risk management e rollback planning
- ‚úÖ Testing e valida√ß√£o
- ‚úÖ Documenta√ß√£o t√©cnica

---

**Autor:** Marcelo Loiola  
**Data:** Janeiro 2026  
**Status:** ‚úÖ Implementado e Validado
