# Metodologia SRE: Resource Optimization

## Vis√£o Geral

Este documento descreve a metodologia Site Reliability Engineering (SRE) aplicada para otimiza√ß√£o de recursos em clusters Kubernetes, com foco em **Right-Sizing** de CPU e Mem√≥ria.

A abordagem √© **data-driven**, **iterativa** e **orientada a riscos**, seguindo as melhores pr√°ticas do Google SRE.

---

## Princ√≠pios Fundamentais

### 1. Observabilidade Primeiro

> "You can't improve what you don't measure" - Peter Drucker

**Requisitos:**
- ‚úÖ Metrics-server funcional
- ‚úÖ Prometheus/Grafana (opcional mas recomendado)
- ‚úÖ Hist√≥rico m√≠nimo de 7 dias
- ‚úÖ Alertas configurados

### 2. Data-Driven Decisions

Todas as decis√µes devem ser baseadas em:
- Uso real medido (n√£o estimativas)
- Tend√™ncias hist√≥ricas (n√£o momentos isolados)
- An√°lise de percentis (P95, P99)
- Correla√ß√£o com eventos de neg√≥cio

### 3. Itera√ß√£o Gradual

```
Piloto ‚Üí Valida√ß√£o ‚Üí Escala ‚Üí Automa√ß√£o
```

Nunca otimize tudo de uma vez. Comece pequeno, valide, aprenda, escale.

### 4. Margem de Seguran√ßa

```
Request = Uso_de_Pico √ó Margem_de_Seguran√ßa
```

**Margens recomendadas:**
- Aplica√ß√µes cr√≠ticas: 1.5-2.0x
- Aplica√ß√µes est√°veis: 1.3-1.5x
- DaemonSets previs√≠veis: at√© 7x
- Jobs/CronJobs: 1.2-1.5x

---

## O Ciclo de Otimiza√ß√£o

### Fase 1: DISCOVERY (Descoberta)

**Objetivo:** Identificar onde est√° o desperd√≠cio

**Ferramentas:**
- Scripts de auditoria automatizados
- Dashboards de observabilidade
- An√°lise de trends

**Entreg√°vel:**
```
Ranking de namespaces por:
1. Slack absoluto (millicores desperdi√ßados)
2. Percentual de desperd√≠cio
3. Impacto no cluster (%)
```

**Exemplo de Output:**
```
NAMESPACE          REQUESTED   USED    SLACK    WASTE%   PRIORITY
velero             560m        6m      554m     98.9%    üî¥ ALTA
istio-system       1410m       21m     1389m    98.5%    üî¥ ALTA
monitoring         950m        111m    839m     88.3%    üü° M√âDIA
kube-system        3925m       625m    3300m    84.1%    üü° M√âDIA
```

---

### Fase 2: ANALYSIS (An√°lise)

**Objetivo:** Entender o comportamento de cada workload

**Checklist de An√°lise:**

```bash
# 1. Identificar tipo de workload
kubectl get all -n <namespace>
‚Üí Deployment, StatefulSet, DaemonSet?

# 2. Listar requests atuais
kubectl get pods -n <namespace> -o custom-columns='...'
‚Üí Quanto cada pod pede?

# 3. Verificar uso real
kubectl top pods -n <namespace>
‚Üí Quanto cada pod usa?

# 4. An√°lise de containers individuais
kubectl get pod <nome> -n <namespace> -o jsonpath='...'
‚Üí App vs Sidecar?

# 5. Hist√≥rico no Prometheus
‚Üí √öltimos 7-30 dias
‚Üí P50, P95, P99
‚Üí Picos correlacionados com eventos?

# 6. Fun√ß√£o do workload
‚Üí O que essa aplica√ß√£o faz?
‚Üí Quando ela trabalha mais?
‚Üí √â cr√≠tica para o neg√≥cio?
```

**Matriz de Criticidade:**

| Tipo | Criticidade | Abordagem |
|------|-------------|-----------|
| **Infraestrutura cr√≠tica** (kube-system, istio) | ALTA | Conservador, margem 2x |
| **Aplica√ß√µes de neg√≥cio** (prod) | ALTA | Conservador, margem 1.5-2x |
| **Ferramentas auxiliares** (velero, monitoring) | M√âDIA | Moderado, margem 1.3-1.5x |
| **Ambientes n√£o-prod** (dev, hml) | BAIXA | Agressivo, margem 1.2x |

---

### Fase 3: PLANNING (Planejamento)

**Objetivo:** Definir valores seguros e estrat√©gia de implementa√ß√£o

**Template de Planejamento:**

```yaml
Namespace: velero
Criticidade: M√âDIA
Data da An√°lise: 2026-01-31

Workload 1:
  Nome: node-agent
  Tipo: DaemonSet
  Pods: 3
  Request Atual: 20m por pod
  Uso M√©dio: 0.5m
  Uso P95: 0.7m
  Uso Pico: 1m
  Request Proposto: 5m
  Justificativa: Uso extremamente est√°vel, margem de 7x √© segura
  Risco: BAIXO

Workload 2:
  Nome: velero
  Tipo: Deployment
  Pods: 1
  Request Atual: 500m
  Uso M√©dio: 5m
  Uso P95: 12m
  Uso Pico: 15m
  Request Proposto: 30m
  Justificativa: Picos durante backups (curtos), margem de 2x
  Risco: BAIXO

Economia Total: 515m (92%)
Rollback Plan: kubectl rollout undo
Valida√ß√£o: Monitorar 24h, testar backup manual
```

---

### Fase 4: IMPLEMENTATION (Implementa√ß√£o)

**Objetivo:** Aplicar mudan√ßas de forma segura e revers√≠vel

**Processo:**

1. **Criar script de corre√ß√£o**
```bash
#!/bin/bash
# correcao_<namespace>.sh

# Dry-run primeiro
echo "=== DRY RUN ==="
echo "Comando que ser√° executado:"
echo "kubectl patch ..."
echo ""
read -p "Continuar? (y/n) " -n 1 -r
echo

if [[ $REPLY =~ ^[Yy]$ ]]; then
    # Aplicar mudan√ßas
    kubectl patch ...
fi
```

2. **Executar em hor√°rio de baixo movimento**
   - Evitar hor√°rio comercial para prod
   - Dev/Hml pode ser a qualquer momento

3. **Aplicar uma mudan√ßa por vez**
   - DaemonSet primeiro
   - Aguardar pods estabilizarem
   - Depois Deployment
   - Aguardar estabilizar

4. **Monitorar ativamente**
```bash
# Terminal 1: Watch pods
watch -n 2 kubectl get pods -n <namespace>

# Terminal 2: Watch events
kubectl get events -n <namespace> --watch

# Terminal 3: Watch metrics
watch -n 5 kubectl top pods -n <namespace>
```

---

### Fase 5: VALIDATION (Valida√ß√£o)

**Objetivo:** Confirmar que mudan√ßas n√£o causaram problemas

**Checklist de Valida√ß√£o:**

```bash
# ‚úÖ 1. Pods est√£o rodando?
kubectl get pods -n <namespace>
‚Üí Todos em Running?
‚Üí Nenhum CrashLoopBackOff?
‚Üí Restarts normais?

# ‚úÖ 2. Novos valores aplicados?
kubectl get pods -n <namespace> -o custom-columns='...'
‚Üí Requests atualizados corretamente?

# ‚úÖ 3. Sem eventos de erro?
kubectl get events -n <namespace> --sort-by='.lastTimestamp'
‚Üí Sem OOMKilled?
‚Üí Sem Evicted?
‚Üí Sem FailedScheduling?

# ‚úÖ 4. M√©tricas est√°veis?
kubectl top pods -n <namespace>
‚Üí Uso dentro do esperado?
‚Üí Sem throttling vis√≠vel?

# ‚úÖ 5. Funcionalidade OK?
# Executar testes espec√≠ficos da aplica√ß√£o
‚Üí Velero: rodar backup manual
‚Üí Istio: verificar traffic routing
‚Üí App: health checks, smoke tests

# ‚úÖ 6. Sem alertas disparados?
# Verificar Prometheus/Alertmanager
‚Üí Nenhum alerta novo?
‚Üí SLOs mantidos?
```

**Per√≠odo de Valida√ß√£o:**
- Cr√≠tico: 7 dias
- M√©dio: 3 dias  
- Baixo: 24 horas

---

### Fase 6: MONITORING (Monitoramento)

**Objetivo:** Garantir que otimiza√ß√£o se mant√©m saud√°vel

**M√©tricas para Monitorar:**

```yaml
M√©tricas de CPU:
  - container_cpu_usage_seconds_total
  - container_cpu_cfs_throttled_seconds_total
  - kube_pod_container_resource_requests_cpu_cores
  
M√©tricas de Mem√≥ria:
  - container_memory_usage_bytes
  - container_memory_working_set_bytes
  - kube_pod_container_resource_requests_memory_bytes
  
M√©tricas de QoS:
  - kube_pod_status_qos_class
  - kube_node_status_allocatable
```

**Alertas Recomendados:**

```yaml
# Alerta: CPU Throttling Alto
alert: HighCPUThrottling
expr: |
  rate(container_cpu_cfs_throttled_seconds_total[5m]) > 0.25
for: 10m
annotations:
  summary: "Pod {{ $labels.pod }} est√° com throttling alto"
  
# Alerta: Aproximando do Request
alert: CPUNearRequest
expr: |
  container_cpu_usage_seconds_total / 
  kube_pod_container_resource_requests_cpu_cores > 0.8
for: 30m
annotations:
  summary: "Pod {{ $labels.pod }} usando 80%+ do request"
```

---

## Ferramentas e Automa√ß√£o

### Scripts Essenciais

1. **check_slack_percent.sh** - Auditoria peri√≥dica
2. **diagnostico_metrics.sh** - Validar pr√©-requisitos
3. **correcao_<namespace>.sh** - Aplicar otimiza√ß√µes

### Automa√ß√£o Cont√≠nua

```bash
# Cron job para auditoria semanal
0 9 * * 1 /path/to/check_slack_percent.sh > /var/log/k8s-audit-$(date +\%Y\%m\%d).log

# Notificar se desperd√≠cio > 80%
0 9 * * 1 /path/to/check_slack_percent.sh | awk '$5 > 80' | mail -s "Alerta: Desperd√≠cio Alto" sre@empresa.com
```

### Integra√ß√£o com CI/CD

```yaml
# GitLab CI example
audit-resources:
  script:
    - ./check_slack_percent.sh
    - ./analyze_results.sh
  only:
    - schedules
  artifacts:
    reports:
      metrics: audit_report.json
```

---

## KPIs e M√©tricas de Sucesso

### M√©tricas de Efici√™ncia

```
Efici√™ncia do Cluster = (CPU_Usado / CPU_Solicitado) √ó 100

Ideal: 60-80%
Aceit√°vel: 40-60%
Ruim: <40%
Perigoso: >90% (pode indicar under-provisioning)
```

### M√©tricas de Impacto

- **Recursos Liberados:** Millicores e MiB economizados
- **Percentual de Economia:** (Slack_Antes - Slack_Depois) / Slack_Antes
- **ROI Financeiro:** Economia √ó Custo por Recurso
- **Namespaces Otimizados:** Contagem

### M√©tricas de Qualidade

- **Incidentes Relacionados:** 0 √© a meta
- **Downtime Causado:** 0 segundos
- **SLO Mantido:** 100%
- **Revers√µes Necess√°rias:** 0

---

## Gerenciamento de Riscos

### Classifica√ß√£o de Risco

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **OOMKilled** | Baixa | Alto | Margem de seguran√ßa, monitoramento |
| **CPU Throttling** | Baixa | M√©dio | Requests generosos, valida√ß√£o |
| **Downtime** | Muito Baixa | Alto | Rolling update, rollback plan |
| **Degrada√ß√£o** | Baixa | M√©dio | Testes funcionais, per√≠odo de valida√ß√£o |

### Plano de Rollback

**Cen√°rio 1: Pod n√£o inicia**
```bash
# Verificar eventos
kubectl describe pod <nome> -n <namespace>

# Se for request muito baixo, aumentar
kubectl patch deployment <nome> -n <namespace> --type='json' \
  -p='[{"op": "replace", "path": "...", "value": "50m"}]'
```

**Cen√°rio 2: OOMKilled**
```bash
# Aumentar memory request/limit
kubectl patch deployment <nome> -n <namespace> --type='json' \
  -p='[
    {"op": "replace", "path": ".../requests/memory", "value": "256Mi"},
    {"op": "replace", "path": ".../limits/memory", "value": "512Mi"}
  ]'
```

**Cen√°rio 3: Performance degradada**
```bash
# Reverter completamente
kubectl rollout undo deployment/<nome> -n <namespace>

# Ou aumentar requests gradualmente
# 30m ‚Üí 50m ‚Üí 100m at√© estabilizar
```

---

## üí° Boas Pr√°ticas

### Do's ‚úÖ

- ‚úÖ Sempre analise dados antes de agir
- ‚úÖ Comece por namespaces n√£o-cr√≠ticos
- ‚úÖ Mantenha margem de seguran√ßa adequada
- ‚úÖ Documente todas as mudan√ßas
- ‚úÖ Monitore ap√≥s cada mudan√ßa
- ‚úÖ Automatize o processo
- ‚úÖ Compartilhe conhecimento com o time

### Don'ts ‚ùå

- ‚ùå N√£o confie apenas em uso m√©dio
- ‚ùå N√£o otimize tudo de uma vez
- ‚ùå N√£o ignore picos de uso
- ‚ùå N√£o esque√ßa dos sidecars
- ‚ùå N√£o pule a fase de valida√ß√£o
- ‚ùå N√£o fa√ßa em hor√°rio de pico (prod)
- ‚ùå N√£o deixe de ter rollback plan

---

## Checklist do SRE

Antes de iniciar otimiza√ß√£o:

```
[ ] Metrics-server funcionando
[ ] Acesso necess√°rio (kubectl, cluster)
[ ] Hist√≥rico de m√©tricas dispon√≠vel (7+ dias)
[ ] Janela de manuten√ß√£o definida (se necess√°rio)
[ ] Time avisado sobre mudan√ßas
[ ] Rollback plan documentado
[ ] Alertas configurados
```

Durante a otimiza√ß√£o:

```
[ ] Script de corre√ß√£o testado (dry-run)
[ ] Monitoramento ativo em m√∫ltiplos terminais
[ ] Comunica√ß√£o aberta com time
[ ] Log de todas as a√ß√µes
```

Ap√≥s otimiza√ß√£o:

```
[ ] Valida√ß√£o completa executada
[ ] Documenta√ß√£o atualizada
[ ] M√©tricas de sucesso coletadas
[ ] Li√ß√µes aprendidas registradas
[ ] Pr√≥ximos alvos identificados
```

---

## Refer√™ncias

- [Google SRE Book](https://sre.google/sre-book/table-of-contents/)
- [Kubernetes Best Practices](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/)
- [CNCF Cloud Native Glossary](https://glossary.cncf.io/)
- [Prometheus Best Practices](https://prometheus.io/docs/practices/)

---

## Contribuindo

Esta metodologia √© viva e deve evoluir. Contribua com:

- Li√ß√µes aprendidas de casos reais
- Novas ferramentas e automa√ß√µes
- M√©tricas e KPIs relevantes
- Estudos de caso detalhados

---

**Autor:** Marcelo Loiola  
**Vers√£o:** 1.0  
**Data:** Janeiro 2026  
**Status:** ‚úÖ Validado em Produ√ß√£o
